{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Building the _\"evolution\"_ research papers dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Lu\u00eds F. Sim\u00f5es](mailto:luis.simoes@vu.nl)<br>\n",
      "2013-10-29 (*updated: 2013-11-02*)<br><br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The [Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) module, a part of the [Biopython](http://biopython.org/) library, will be used to interface with [PubMed](http://www.ncbi.nlm.nih.gov/pubmed).<br>\n",
      "You can download Biopython from [here](http://biopython.org/wiki/Download).\n",
      "\n",
      "In this notebook we will be covering several of the steps taken in the [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html), specifically in [Chapter 9  Accessing NCBI\u2019s Entrez databases](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc109)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      "\n",
      "# NCBI requires you to set your email address to make use of NCBI's E-utilities\n",
      "Entrez.email = \"Your.Name.Here@example.org\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The datasets will be saved as serialized Python objects, compressed with bzip2.\n",
      "Saving/loading them will therefore require the [cPickle](http://docs.python.org/2/library/pickle.html) and [bz2](http://docs.python.org/2/library/bz2.html) modules."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle, bz2\n",
      "import os\n",
      "\n",
      "# data format used in Python object serialization\n",
      "pickle_protocol = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "EInfo: Obtaining information about the Entrez databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.einfo()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc111), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#einfo), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EInfo).\n",
      "</div>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# accessing extended information about the PubMed database\n",
      "pubmed = Entrez.read( Entrez.einfo(db=\"pubmed\"), validate=False )[u'DbInfo']\n",
      "\n",
      "# list of possible search fields for use with ESearch:\n",
      "search_fields = { f['Name']:f['Description'] for f in pubmed[\"FieldList\"] }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In search_fields, we find 'TIAB' ('Free text associated with Abstract/Title') as a possible search field to use in searches."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "{'AFFL': \"Author's institutional affiliation and address\",\n",
        " 'ALL': 'All terms from all searchable fields',\n",
        " 'AUCL': 'Author Cluster ID',\n",
        " 'AUID': 'Author Identifier',\n",
        " 'AUTH': 'Author(s) of publication',\n",
        " 'BOOK': 'ID of the book that contains the document',\n",
        " 'CDAT': 'Date of completion',\n",
        " 'CNTY': 'Country of publication',\n",
        " 'COLN': 'Corporate Author of publication',\n",
        " 'CRDT': 'Date publication first accessible through Entrez',\n",
        " 'DSO': 'Additional text from the summary',\n",
        " 'ECNO': 'EC number for enzyme or CAS registry number',\n",
        " 'ED': \"Section's Editor\",\n",
        " 'EDAT': 'Date publication first accessible through Entrez',\n",
        " 'EID': 'Extended PMID',\n",
        " 'EPDT': 'Date of Electronic publication',\n",
        " 'FAUT': 'First Author of publication',\n",
        " 'FILT': 'Limits the records',\n",
        " 'FINV': 'Full name of investigator',\n",
        " 'FULL': 'Full Author Name(s) of publication',\n",
        " 'GRNT': 'NIH Grant Numbers',\n",
        " 'INVR': 'Investigator',\n",
        " 'ISBN': 'ISBN',\n",
        " 'ISS': 'Issue number of publication',\n",
        " 'JOUR': 'Journal abbreviation of publication',\n",
        " 'LANG': 'Language of publication',\n",
        " 'LAUT': 'Last Author of publication',\n",
        " 'LID': 'ELocation ID',\n",
        " 'MAJR': 'MeSH terms of major importance to publication',\n",
        " 'MDAT': 'Date of last modification',\n",
        " 'MESH': 'Medical Subject Headings assigned to publication',\n",
        " 'MHDA': 'Date publication was indexed with MeSH terms',\n",
        " 'OTRM': 'Other terms associated with publication',\n",
        " 'PAGE': 'Page number(s) of publication',\n",
        " 'PAPX': 'MeSH pharmacological action pre-explosions',\n",
        " 'PDAT': 'Date of publication',\n",
        " 'PID': 'Publisher ID',\n",
        " 'PPDT': 'Date of print publication',\n",
        " 'PTYP': 'Type of publication (e.g., review)',\n",
        " 'PUBN': \"Publisher's name\",\n",
        " 'SI': 'Cross-reference from publication to other databases',\n",
        " 'SUBH': 'Additional specificity for MeSH term',\n",
        " 'SUBS': 'CAS chemical name or MEDLINE Substance Name',\n",
        " 'TIAB': 'Free text associated with Abstract/Title',\n",
        " 'TITL': 'Words in title of publication',\n",
        " 'TT': 'Words in transliterated title of publication',\n",
        " 'UID': 'Unique number assigned to publication',\n",
        " 'VOL': 'Volume number of publication',\n",
        " 'WORD': 'Free text associated with publication'}"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ESearch: Searching the Entrez databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.esearch()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc112), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#esearch), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch).\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have a look at the kind of data we get when searching the database, we'll perform a search for papers authored by Haasdijk:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_authors = ['Haasdijk E']\n",
      "example_search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=' AND '.join([a+'[AUTH]' for a in example_authors]) ) )\n",
      "example_search"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "{u'Count': '25', u'RetMax': '20', u'IdList': ['23580075', '23144668', '22174697', '22154920', '21870131', '21760539', '20662596', '20602234', '20386726', '18579581', '18305242', '17913916', '17804640', '17686042', '17183535', '16262628', '15899262', '15245475', '12457735', '11603803'], u'TranslationStack': [{u'Count': '25', u'Field': 'AUTH', u'Term': 'Haasdijk E[AUTH]', u'Explode': 'N'}, 'GROUP'], u'TranslationSet': [], u'RetStart': '0', u'QueryTranslation': 'Haasdijk E[AUTH]'}"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note how the result being produced is not in Python's native string format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type( example_search['IdList'][0] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Bio.Entrez.Parser.StringElement"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The part of the query's result we are most interested in is accessible through"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_ids = [ int(id) for id in example_search['IdList'] ]\n",
      "print example_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[23580075, 23144668, 22174697, 22154920, 21870131, 21760539, 20662596, 20602234, 20386726, 18579581, 18305242, 17913916, 17804640, 17686042, 17183535, 16262628, 15899262, 15245475, 12457735, 11603803]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "PubMed IDs dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now assemble a dataset comprised of research articles containing the keyword \"evolution\", in either their titles or abstracts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_term = 'evolution'\n",
      "\n",
      "Ids_file = search_term + '__Ids.pkl.bz2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.exists( Ids_file ):\n",
      "    Ids = cPickle.load( bz2.BZ2File( Ids_file, 'rb' ) )\n",
      "else:\n",
      "    # determine the number of hits for the search term\n",
      "    search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retmax=0 ) )\n",
      "    total = int( search['Count'] )\n",
      "    \n",
      "    # `Ids` will be incrementally assembled, by performing multiple queries,\n",
      "    # each returning at most `retrieve_per_query` entries.\n",
      "    Ids_str = []\n",
      "    retrieve_per_query = 10000\n",
      "    \n",
      "    for start in xrange( 0, total, retrieve_per_query ):\n",
      "        print 'Fetching IDs of results [%d,%d]' % ( start, start+retrieve_per_query )\n",
      "        s = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retstart=start, retmax=retrieve_per_query ) )\n",
      "        Ids_str.extend( s[ u'IdList' ] )\n",
      "    \n",
      "    # convert Ids to integers (and ensure that the conversion is reversible)\n",
      "    Ids = [ int(id) for id in Ids_str ]\n",
      "    \n",
      "    for (id_str, id_int) in zip(Ids_str, Ids):\n",
      "        if str(id_int) != id_str:\n",
      "            raise Exception('Conversion of PubMed ID %s from string to integer it not reversible.' % id_str )\n",
      "    \n",
      "    # Save list of Ids\n",
      "    cPickle.dump( Ids, bz2.BZ2File( Ids_file, 'wb' ), protocol=pickle_protocol )\n",
      "    \n",
      "total = len( Ids )\n",
      "print '%d documents contain the search term \"%s\".' % ( total, search_term )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "205344 documents contain the search term \"evolution\".\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking a look at what we just retrieved, here are the last 5 elements of the `Ids` list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ids[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[24159039, 24159033, 24158817, 24158684, 24158625]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ESummary: Retrieving summaries from primary IDs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.esummary()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc114), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#esummary), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESummary).\n",
      "</div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have a look at the kind of metadata we get from a call to `Entrez.esummary()`, we now fetch the summary of one of Haasdijk's papers (using one of the PubMed IDs we obtained in the [previous section](#ESearch:-Searching-the-Entrez-databases)):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_paper = Entrez.read( Entrez.esummary(db=\"pubmed\", id='23144668') )[0]\n",
      "\n",
      "def print_summary( p ):\n",
      "    for k,v in p.items():\n",
      "        print k\n",
      "        print '\\t',v\n",
      "\n",
      "print_summary(example_paper)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DOI\n",
        "\t10.1007/s12065-012-0071-x\n",
        "Title\n",
        "\tEmbodied artificial evolution: Artificial evolutionary systems in the 21st Century.\n",
        "Source\n",
        "\tEvol Intell\n",
        "PmcRefCount\n",
        "\t0\n",
        "Issue\n",
        "\t4\n",
        "SO\n",
        "\t2012 Dec;5(4):261-272\n",
        "ISSN\n",
        "\t1864-5909\n",
        "Volume\n",
        "\t5\n",
        "FullJournalName\n",
        "\tEvolutionary intelligence\n",
        "RecordStatus\n",
        "\tPubMed\n",
        "ESSN\n",
        "\t1864-5917\n",
        "ELocationID\n",
        "\t\n",
        "Pages\n",
        "\t261-272\n",
        "PubStatus\n",
        "\tppublish+epublish\n",
        "AuthorList\n",
        "\t['Eiben AE', 'Kernbach S', 'Haasdijk E']\n",
        "EPubDate\n",
        "\t2012 Apr 20\n",
        "PubDate\n",
        "\t2012 Dec\n",
        "NlmUniqueID\n",
        "\t101475575\n",
        "LastAuthor\n",
        "\tHaasdijk E\n",
        "ArticleIds\n",
        "\t{'pii': '71', 'medline': [], 'pubmed': ['23144668'], 'eid': '23144668', 'pmc': 'PMC3490067', 'rid': '23144668', 'pmcid': 'pmc-id: PMC3490067;', 'doi': '10.1007/s12065-012-0071-x'}\n",
        "Item\n",
        "\t[]\n",
        "History\n",
        "\t{'received': '2011/11/28 00:00', 'medline': ['2012/11/13 06:00'], 'revised': '2012/02/17 00:00', 'pubmed': ['2012/11/13 06:00'], 'epublish': '2012/04/20 00:00', 'accepted': '2012/03/22 00:00', 'entrez': '2012/11/13 06:00'}\n",
        "LangList\n",
        "\t['English']\n",
        "HasAbstract\n",
        "\t1\n",
        "References\n",
        "\t[]\n",
        "PubTypeList\n",
        "\t['Journal Article']\n",
        "Id\n",
        "\t23144668\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For now, we'll keep just some basic information for each paper: title, list of authors, publication year, and [DOI](https://en.wikipedia.org/wiki/Digital_object_identifier).\n",
      "\n",
      "In case you are not familiar with the DOI system, know that the paper above can be accessed through the link [http://dx.doi.org/10.1007/s12065-012-0071-x](http://dx.doi.org/10.1007/s12065-012-0071-x) (which is `http://dx.doi.org/` followed by the paper's DOI)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "( example_paper['Title'], example_paper['AuthorList'], int(example_paper['PubDate'][:4]), example_paper['DOI'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "('Embodied artificial evolution: Artificial evolutionary systems in the 21st Century.',\n",
        " ['Eiben AE', 'Kernbach S', 'Haasdijk E'],\n",
        " 2012,\n",
        " '10.1007/s12065-012-0071-x')"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Summaries dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now ready to assemble a dataset containing the summaries of all the paper `Ids` we previously fetched.\n",
      "\n",
      "To reduce the memory footprint, and to ensure the saved datasets won't depend on Biopython being installed to be properly loaded, values returned by `Entrez.read()` will be converted to their corresponding native Python types. We start by defining a function for helping with the conversion of strings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def conv_str( s ):\n",
      "    \"\"\"\n",
      "    The Entrez parser returns strings as either instances of\n",
      "    `Bio.Entrez.Parser.StringElement` (a subclass of `str`),\n",
      "    or `Bio.Entrez.Parser.UnicodeElement` (a subclass of `unicode`).\n",
      "    Such strings are here converted to Python's native formats.\n",
      "    \n",
      "    See: http://biopython.org/DIST/docs/api/Bio.Entrez.Parser-pysrc.html\n",
      "    \"\"\"\n",
      "    return unicode(s) if isinstance(s, unicode) else str(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Summaries_file = search_term + '__Summaries.pkl.bz2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.exists( Summaries_file ):\n",
      "    Summaries = cPickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
      "else:\n",
      "    # `Summaries` will be incrementally assembled, by performing multiple queries,\n",
      "    # each returning at most `retrieve_per_query` entries.\n",
      "    Summaries = []\n",
      "    retrieve_per_query = 200\n",
      "    \n",
      "    print 'Fetching Summaries of results: ',\n",
      "    for start in xrange( 0, len(Ids), retrieve_per_query ):\n",
      "        print start,\n",
      "        \n",
      "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
      "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
      "        \n",
      "        s = Entrez.read( Entrez.esummary( db=\"pubmed\", id=query_ids ) )\n",
      "        \n",
      "        # out of the retrieved data, we will keep only a tuple (title, authors, year, DOI), associated with the paper's id.\n",
      "        # (all values converted to native Python formats)\n",
      "        f = [\n",
      "            ( int( p['Id'] ), (\n",
      "                conv_str( p['Title'] ),\n",
      "                [ conv_str(a) for a in p['AuthorList'] ],\n",
      "                int( p['PubDate'][:4] ),                # keeps just the publication year\n",
      "                conv_str( p.get('DOI', '') )            # papers for which no DOI is available get an empty string in their place\n",
      "                ) )\n",
      "            for p in s\n",
      "            ]\n",
      "        Summaries.extend( f )\n",
      "    \n",
      "    # Save Summaries, as a dictionary indexed by Ids\n",
      "    Summaries = dict( Summaries )\n",
      "    \n",
      "    cPickle.dump( Summaries, bz2.BZ2File( Summaries_file, 'wb' ), protocol=pickle_protocol )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us take a look at the first 3 retrieved summaries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{ id : Summaries[id] for id in Ids[:3] }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "{24158817: ('HIV-1 Rev Function and RNA Nuclear-Cytoplasmic Export.',\n",
        "  ['Cochrane A'],\n",
        "  2014,\n",
        "  '10.1007/978-1-62703-670-2_9'),\n",
        " 24159033: ('Evolution. Natural selection and pain meet at a sodium channel.',\n",
        "  ['Lewin GR'],\n",
        "  2013,\n",
        "  '10.1126/science.1244375'),\n",
        " 24159039: ('Voltage-gated sodium channel in grasshopper mice defends against bark scorpion toxin.',\n",
        "  ['Rowe AH', 'Xiao Y', 'Rowe MP', 'Cummins TR', 'Zakon HH'],\n",
        "  2013,\n",
        "  '10.1126/science.1236451')}"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Where do we go from here?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running the code above generates multiple local files, containing the datasets we'll be working with. Loading them into memory is a matter of just issuing a call like<br>\n",
      "``data = cPickle.load( bz2.BZ2File( data_file, 'rb' ) )``.\n",
      "\n",
      "The Entrez module will therefore no longer be needed, unless you wish to extend your data processing with additional information retrieved from PubMed.\n",
      "\n",
      "Should you be interested in looking at alternative ways to handle the data, have a look at the [sqlite3](http://docs.python.org/2/library/sqlite3.html) module included in Python's standard library, or [Pandas](http://pandas.pydata.org/), the Python Data Analysis Library."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}