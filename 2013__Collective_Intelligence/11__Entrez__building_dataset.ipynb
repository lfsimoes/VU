{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Building the _\"evolution\"_ research papers dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Lu\u00eds F. Sim\u00f5es](mailto:luis.simoes@vu.nl)<br>\n",
      "2013-10-29 *(updated: 2013-11-08)*<div style=\"float: right\">`Notebooks:` [next &rarr;](http://nbviewer.ipython.org/urls/raw.github.com/lfsimoes/VU/master/2013__Collective_Intelligence/12__inspecting_the_data.ipynb) &bull; [index &uarr;](https://github.com/lfsimoes/VU/tree/master/2013__Collective_Intelligence)</div><br><br>\n",
      "\n",
      "*******"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The [Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) module, a part of the [Biopython](http://biopython.org/) library, will be used to interface with [PubMed](http://www.ncbi.nlm.nih.gov/pubmed).<br>\n",
      "You can download Biopython from [here](http://biopython.org/wiki/Download).\n",
      "\n",
      "In this notebook we will be covering several of the steps taken in the [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html), specifically in [Chapter 9  Accessing NCBI\u2019s Entrez databases](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc109)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import Entrez\n",
      "\n",
      "# NCBI requires you to set your email address to make use of NCBI's E-utilities\n",
      "Entrez.email = \"Your.Name.Here@example.org\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The datasets will be saved as serialized Python objects, compressed with bzip2.\n",
      "Saving/loading them will therefore require the [cPickle](http://docs.python.org/2/library/pickle.html) and [bz2](http://docs.python.org/2/library/bz2.html) modules."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle, bz2\n",
      "import os\n",
      "\n",
      "# data format used in Python object serialization\n",
      "pickle_protocol = 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "EInfo: Obtaining information about the Entrez databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.einfo()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc111), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#einfo), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EInfo).\n",
      "</div><br><br>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# accessing extended information about the PubMed database\n",
      "pubmed = Entrez.read( Entrez.einfo(db=\"pubmed\"), validate=False )[u'DbInfo']\n",
      "\n",
      "# list of possible search fields for use with ESearch:\n",
      "search_fields = { f['Name']:f['Description'] for f in pubmed[\"FieldList\"] }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In search_fields, we find 'TIAB' ('Free text associated with Abstract/Title') as a possible search field to use in searches."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_fields"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "{'AFFL': \"Author's institutional affiliation and address\",\n",
        " 'ALL': 'All terms from all searchable fields',\n",
        " 'AUCL': 'Author Cluster ID',\n",
        " 'AUID': 'Author Identifier',\n",
        " 'AUTH': 'Author(s) of publication',\n",
        " 'BOOK': 'ID of the book that contains the document',\n",
        " 'CDAT': 'Date of completion',\n",
        " 'CNTY': 'Country of publication',\n",
        " 'COLN': 'Corporate Author of publication',\n",
        " 'CRDT': 'Date publication first accessible through Entrez',\n",
        " 'DSO': 'Additional text from the summary',\n",
        " 'ECNO': 'EC number for enzyme or CAS registry number',\n",
        " 'ED': \"Section's Editor\",\n",
        " 'EDAT': 'Date publication first accessible through Entrez',\n",
        " 'EID': 'Extended PMID',\n",
        " 'EPDT': 'Date of Electronic publication',\n",
        " 'FAUT': 'First Author of publication',\n",
        " 'FILT': 'Limits the records',\n",
        " 'FINV': 'Full name of investigator',\n",
        " 'FULL': 'Full Author Name(s) of publication',\n",
        " 'GRNT': 'NIH Grant Numbers',\n",
        " 'INVR': 'Investigator',\n",
        " 'ISBN': 'ISBN',\n",
        " 'ISS': 'Issue number of publication',\n",
        " 'JOUR': 'Journal abbreviation of publication',\n",
        " 'LANG': 'Language of publication',\n",
        " 'LAUT': 'Last Author of publication',\n",
        " 'LID': 'ELocation ID',\n",
        " 'MAJR': 'MeSH terms of major importance to publication',\n",
        " 'MDAT': 'Date of last modification',\n",
        " 'MESH': 'Medical Subject Headings assigned to publication',\n",
        " 'MHDA': 'Date publication was indexed with MeSH terms',\n",
        " 'OTRM': 'Other terms associated with publication',\n",
        " 'PAGE': 'Page number(s) of publication',\n",
        " 'PAPX': 'MeSH pharmacological action pre-explosions',\n",
        " 'PDAT': 'Date of publication',\n",
        " 'PID': 'Publisher ID',\n",
        " 'PPDT': 'Date of print publication',\n",
        " 'PTYP': 'Type of publication (e.g., review)',\n",
        " 'PUBN': \"Publisher's name\",\n",
        " 'SI': 'Cross-reference from publication to other databases',\n",
        " 'SUBH': 'Additional specificity for MeSH term',\n",
        " 'SUBS': 'CAS chemical name or MEDLINE Substance Name',\n",
        " 'TIAB': 'Free text associated with Abstract/Title',\n",
        " 'TITL': 'Words in title of publication',\n",
        " 'TT': 'Words in transliterated title of publication',\n",
        " 'UID': 'Unique number assigned to publication',\n",
        " 'VOL': 'Volume number of publication',\n",
        " 'WORD': 'Free text associated with publication'}"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ESearch: Searching the Entrez databases"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.esearch()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc112), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#esearch), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESearch).\n",
      "</div><br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have a look at the kind of data we get when searching the database, we'll perform a search for papers authored by Haasdijk:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_authors = ['Haasdijk E']\n",
      "example_search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=' AND '.join([a+'[AUTH]' for a in example_authors]) ) )\n",
      "example_search"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "{u'Count': '25', u'RetMax': '20', u'IdList': ['23580075', '23144668', '22174697', '22154920', '21870131', '21760539', '20662596', '20602234', '20386726', '18579581', '18305242', '17913916', '17804640', '17686042', '17183535', '16262628', '15899262', '15245475', '12457735', '11603803'], u'TranslationStack': [{u'Count': '25', u'Field': 'AUTH', u'Term': 'Haasdijk E[AUTH]', u'Explode': 'N'}, 'GROUP'], u'TranslationSet': [], u'RetStart': '0', u'QueryTranslation': 'Haasdijk E[AUTH]'}"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note how the result being produced is not in Python's native string format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type( example_search['IdList'][0] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "Bio.Entrez.Parser.StringElement"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The part of the query's result we are most interested in is accessible through"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_ids = [ int(id) for id in example_search['IdList'] ]\n",
      "print example_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[23580075, 23144668, 22174697, 22154920, 21870131, 21760539, 20662596, 20602234, 20386726, 18579581, 18305242, 17913916, 17804640, 17686042, 17183535, 16262628, 15899262, 15245475, 12457735, 11603803]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "PubMed IDs dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now assemble a dataset comprised of research articles containing the keyword \"evolution\", in either their titles or abstracts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_term = 'evolution'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ids_file = search_term + '__Ids.pkl.bz2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.exists( Ids_file ):\n",
      "    Ids = cPickle.load( bz2.BZ2File( Ids_file, 'rb' ) )\n",
      "else:\n",
      "    # determine the number of hits for the search term\n",
      "    search = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retmax=0 ) )\n",
      "    total = int( search['Count'] )\n",
      "    \n",
      "    # `Ids` will be incrementally assembled, by performing multiple queries,\n",
      "    # each returning at most `retrieve_per_query` entries.\n",
      "    Ids_str = []\n",
      "    retrieve_per_query = 10000\n",
      "    \n",
      "    for start in xrange( 0, total, retrieve_per_query ):\n",
      "        print 'Fetching IDs of results [%d,%d]' % ( start, start+retrieve_per_query )\n",
      "        s = Entrez.read( Entrez.esearch( db=\"pubmed\", term=search_term+'[TIAB]', retstart=start, retmax=retrieve_per_query ) )\n",
      "        Ids_str.extend( s[ u'IdList' ] )\n",
      "    \n",
      "    # convert Ids to integers (and ensure that the conversion is reversible)\n",
      "    Ids = [ int(id) for id in Ids_str ]\n",
      "    \n",
      "    for (id_str, id_int) in zip(Ids_str, Ids):\n",
      "        if str(id_int) != id_str:\n",
      "            raise Exception('Conversion of PubMed ID %s from string to integer it not reversible.' % id_str )\n",
      "    \n",
      "    # Save list of Ids\n",
      "    cPickle.dump( Ids, bz2.BZ2File( Ids_file, 'wb' ), protocol=pickle_protocol )\n",
      "    \n",
      "total = len( Ids )\n",
      "print '%d documents contain the search term \"%s\".' % ( total, search_term )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "205344 documents contain the search term \"evolution\".\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking a look at what we just retrieved, here are the last 5 elements of the `Ids` list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Ids[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[24159039, 24159033, 24158817, 24158684, 24158625]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ESummary: Retrieving summaries from primary IDs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.esummary()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc114), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#esummary), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ESummary).\n",
      "</div><br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have a look at the kind of metadata we get from a call to `Entrez.esummary()`, we now fetch the summary of one of Haasdijk's papers (using one of the PubMed IDs we obtained in the [previous section](#ESearch:-Searching-the-Entrez-databases)):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "example_paper = Entrez.read( Entrez.esummary(db=\"pubmed\", id='23144668') )[0]\n",
      "\n",
      "def print_dict( p ):\n",
      "    for k,v in p.items():\n",
      "        print k\n",
      "        print '\\t',v\n",
      "\n",
      "print_dict(example_paper)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DOI\n",
        "\t10.1007/s12065-012-0071-x\n",
        "Title\n",
        "\tEmbodied artificial evolution: Artificial evolutionary systems in the 21st Century.\n",
        "Source\n",
        "\tEvol Intell\n",
        "PmcRefCount\n",
        "\t0\n",
        "Issue\n",
        "\t4\n",
        "SO\n",
        "\t2012 Dec;5(4):261-272\n",
        "ISSN\n",
        "\t1864-5909\n",
        "Volume\n",
        "\t5\n",
        "FullJournalName\n",
        "\tEvolutionary intelligence\n",
        "RecordStatus\n",
        "\tPubMed\n",
        "ESSN\n",
        "\t1864-5917\n",
        "ELocationID\n",
        "\t\n",
        "Pages\n",
        "\t261-272\n",
        "PubStatus\n",
        "\tppublish+epublish\n",
        "AuthorList\n",
        "\t['Eiben AE', 'Kernbach S', 'Haasdijk E']\n",
        "EPubDate\n",
        "\t2012 Apr 20\n",
        "PubDate\n",
        "\t2012 Dec\n",
        "NlmUniqueID\n",
        "\t101475575\n",
        "LastAuthor\n",
        "\tHaasdijk E\n",
        "ArticleIds\n",
        "\t{'pii': '71', 'medline': [], 'pubmed': ['23144668'], 'eid': '23144668', 'pmc': 'PMC3490067', 'rid': '23144668', 'pmcid': 'pmc-id: PMC3490067;', 'doi': '10.1007/s12065-012-0071-x'}\n",
        "Item\n",
        "\t[]\n",
        "History\n",
        "\t{'received': '2011/11/28 00:00', 'medline': ['2012/11/13 06:00'], 'revised': '2012/02/17 00:00', 'pubmed': ['2012/11/13 06:00'], 'epublish': '2012/04/20 00:00', 'accepted': '2012/03/22 00:00', 'entrez': '2012/11/13 06:00'}\n",
        "LangList\n",
        "\t['English']\n",
        "HasAbstract\n",
        "\t1\n",
        "References\n",
        "\t[]\n",
        "PubTypeList\n",
        "\t['Journal Article']\n",
        "Id\n",
        "\t23144668\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For now, we'll keep just some basic information for each paper: title, list of authors, publication year, and [DOI](https://en.wikipedia.org/wiki/Digital_object_identifier).\n",
      "\n",
      "In case you are not familiar with the DOI system, know that the paper above can be accessed through the link [http://dx.doi.org/10.1007/s12065-012-0071-x](http://dx.doi.org/10.1007/s12065-012-0071-x) (which is `http://dx.doi.org/` followed by the paper's DOI)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "( example_paper['Title'], example_paper['AuthorList'], int(example_paper['PubDate'][:4]), example_paper['DOI'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "('Embodied artificial evolution: Artificial evolutionary systems in the 21st Century.',\n",
        " ['Eiben AE', 'Kernbach S', 'Haasdijk E'],\n",
        " 2012,\n",
        " '10.1007/s12065-012-0071-x')"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Summaries dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are now ready to assemble a dataset containing the summaries of all the paper `Ids` we previously fetched.\n",
      "\n",
      "To reduce the memory footprint, and to ensure the saved datasets won't depend on Biopython being installed to be properly loaded, values returned by `Entrez.read()` will be converted to their corresponding native Python types. We start by defining a function for helping with the conversion of strings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def conv_str( s ):\n",
      "    \"\"\"\n",
      "    The Entrez parser returns strings as either instances of\n",
      "    `Bio.Entrez.Parser.StringElement` (a subclass of `str`),\n",
      "    or `Bio.Entrez.Parser.UnicodeElement` (a subclass of `unicode`).\n",
      "    Such strings are here converted to Python's native formats.\n",
      "    \n",
      "    See: http://biopython.org/DIST/docs/api/Bio.Entrez.Parser-pysrc.html\n",
      "    \"\"\"\n",
      "    return unicode(s) if isinstance(s, unicode) else str(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Summaries_file = search_term + '__Summaries.pkl.bz2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.exists( Summaries_file ):\n",
      "    Summaries = cPickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
      "else:\n",
      "    # `Summaries` will be incrementally assembled, by performing multiple queries,\n",
      "    # each returning at most `retrieve_per_query` entries.\n",
      "    Summaries = []\n",
      "    retrieve_per_query = 200\n",
      "    \n",
      "    print 'Fetching Summaries of results: ',\n",
      "    for start in xrange( 0, len(Ids), retrieve_per_query ):\n",
      "        print start,\n",
      "        \n",
      "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
      "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
      "        \n",
      "        s = Entrez.read( Entrez.esummary( db=\"pubmed\", id=query_ids ) )\n",
      "        \n",
      "        # out of the retrieved data, we will keep only a tuple (title, authors, year, DOI), associated with the paper's id.\n",
      "        # (all values converted to native Python formats)\n",
      "        f = [\n",
      "            ( int( p['Id'] ), (\n",
      "                conv_str( p['Title'] ),\n",
      "                [ conv_str(a) for a in p['AuthorList'] ],\n",
      "                int( p['PubDate'][:4] ),                # keeps just the publication year\n",
      "                conv_str( p.get('DOI', '') )            # papers for which no DOI is available get an empty string in their place\n",
      "                ) )\n",
      "            for p in s\n",
      "            ]\n",
      "        Summaries.extend( f )\n",
      "    \n",
      "    # Save Summaries, as a dictionary indexed by Ids\n",
      "    Summaries = dict( Summaries )\n",
      "    \n",
      "    cPickle.dump( Summaries, bz2.BZ2File( Summaries_file, 'wb' ), protocol=pickle_protocol )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us take a look at the first 3 retrieved summaries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{ id : Summaries[id] for id in Ids[:3] }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "{24158817: ('HIV-1 Rev Function and RNA Nuclear-Cytoplasmic Export.',\n",
        "  ['Cochrane A'],\n",
        "  2014,\n",
        "  '10.1007/978-1-62703-670-2_9'),\n",
        " 24159033: ('Evolution. Natural selection and pain meet at a sodium channel.',\n",
        "  ['Lewin GR'],\n",
        "  2013,\n",
        "  '10.1126/science.1244375'),\n",
        " 24159039: ('Voltage-gated sodium channel in grasshopper mice defends against bark scorpion toxin.',\n",
        "  ['Rowe AH', 'Xiao Y', 'Rowe MP', 'Cummins TR', 'Zakon HH'],\n",
        "  2013,\n",
        "  '10.1126/science.1236451')}"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can find examples of how to use this data in the \"[inspecting the dataset](http://nbviewer.ipython.org/urls/raw.github.com/lfsimoes/VU/master/2013__Collective_Intelligence/12__inspecting_the_data.ipynb)\" notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "EFetch: Downloading full records from Entrez"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.efetch()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc115), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#efetch), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch).\n",
      "</div><br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Entrez.efetch()` is the function that will allow us to obtain paper abstracts. Let us start by taking a look at the kind of data it returns when we query PubMed's database (see in [this table](http://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.chapter4_table1/?report=objectonly) the the databases, data formats, and record views you can access through `Entrez.efetch()`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q = Entrez.read( Entrez.efetch(db=\"pubmed\", id='23144668', retmode=\"xml\") )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`q` is a list, with each member corresponding to a queried id. Because here we only queried for one id, its results are then in `q[0]`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(q), len(q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "(Bio.Entrez.Parser.ListElement, 1)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At `q[0]` we find a dictionary containing two keys, the contents of which we print below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(q[0]), q[0].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(Bio.Entrez.Parser.DictionaryElement, [u'MedlineCitation', u'PubmedData'])"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_dict( q[0][ 'PubmedData' ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ArticleIdList\n",
        "\t[StringElement('10.1007/s12065-012-0071-x', attributes={u'IdType': u'doi'}), StringElement('71', attributes={u'IdType': u'pii'}), StringElement('23144668', attributes={u'IdType': u'pubmed'}), StringElement('PMC3490067', attributes={u'IdType': u'pmc'})]\n",
        "PublicationStatus\n",
        "\tppublish\n",
        "History\n",
        "\t[DictElement({u'Month': '11', u'Day': '28', u'Year': '2011'}, attributes={u'PubStatus': u'received'}), DictElement({u'Month': '2', u'Day': '17', u'Year': '2012'}, attributes={u'PubStatus': u'revised'}), DictElement({u'Month': '3', u'Day': '22', u'Year': '2012'}, attributes={u'PubStatus': u'accepted'}), DictElement({u'Month': '4', u'Day': '20', u'Year': '2012'}, attributes={u'PubStatus': u'epublish'}), DictElement({u'Minute': '0', u'Month': '11', u'Day': '13', u'Hour': '6', u'Year': '2012'}, attributes={u'PubStatus': u'entrez'}), DictElement({u'Minute': '0', u'Month': '11', u'Day': '13', u'Hour': '6', u'Year': '2012'}, attributes={u'PubStatus': u'pubmed'}), DictElement({u'Minute': '0', u'Month': '11', u'Day': '13', u'Hour': '6', u'Year': '2012'}, attributes={u'PubStatus': u'medline'})]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The key `'MedlineCitation'` maps into another dictionary. In that dictionary, most of the information is contained under the key `'Article'`. To minimize the clutter, below we show the contents of `'MedlineCitation'` excluding its `'Article'` member, and below that we then show the contents of `'Article'`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_dict( { k:v for k,v in q[0][ 'MedlineCitation' ].iteritems() if k!='Article' } )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OtherID\n",
        "\t[]\n",
        "OtherAbstract\n",
        "\t[]\n",
        "CitationSubset\n",
        "\t[]\n",
        "KeywordList\n",
        "\t[]\n",
        "DateCreated\n",
        "\t{u'Month': '11', u'Day': '12', u'Year': '2012'}\n",
        "SpaceFlightMission\n",
        "\t[]\n",
        "GeneralNote\n",
        "\t[]\n",
        "PMID\n",
        "\t23144668\n",
        "MedlineJournalInfo\n",
        "\t{u'MedlineTA': 'Evol Intell', u'NlmUniqueID': '101475575', u'ISSNLinking': '1864-5909'}\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_dict( q[0][ 'MedlineCitation' ][ 'Article' ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ArticleDate\n",
        "\t[DictElement({u'Month': '4', u'Day': '20', u'Year': '2012'}, attributes={u'DateType': u'Electronic'})]\n",
        "Pagination\n",
        "\t{u'MedlinePgn': '261-272'}\n",
        "AuthorList\n",
        "\tListElement([DictElement({u'LastName': 'Eiben', u'Initials': 'AE', u'Identifier': [], u'ForeName': 'A E'}, attributes={u'ValidYN': u'Y'}), DictElement({u'LastName': 'Kernbach', u'Initials': 'S', u'Identifier': [], u'ForeName': 'S'}, attributes={u'ValidYN': u'Y'}), DictElement({u'LastName': 'Haasdijk', u'Initials': 'E', u'Identifier': [], u'ForeName': 'Evert'}, attributes={u'ValidYN': u'Y'})], attributes={u'Type': u'authors', u'CompleteYN': u'Y'})\n",
        "Language\n",
        "\t['ENG']\n",
        "PublicationTypeList\n",
        "\t['JOURNAL ARTICLE']\n",
        "Journal\n",
        "\t{u'ISSN': StringElement('1864-5909', attributes={u'IssnType': u'Print'}), u'ISOAbbreviation': 'Evol Intell', u'JournalIssue': DictElement({u'Volume': '5', u'Issue': '4', u'PubDate': {u'Month': 'Dec', u'Year': '2012'}}, attributes={u'CitedMedium': u'Print'}), u'Title': 'Evolutionary intelligence'}\n",
        "Affiliation\n",
        "\tVU University Amsterdam, Amsterdam, The Netherlands.\n",
        "ArticleTitle\n",
        "\tEmbodied artificial evolution: Artificial evolutionary systems in the 21st Century.\n",
        "ELocationID\n",
        "\t[]\n",
        "Abstract\n",
        "\t{u'AbstractText': ['Evolution is one of the major omnipresent powers in the universe that has been studied for about two centuries. Recent scientific and technical developments make it possible to make the transition from passively understanding to actively using evolutionary processes. Today this is possible in Evolutionary Computing, where human experimenters can design and manipulate all components of evolutionary processes in digital spaces. We argue that in the near future it will be possible to implement artificial evolutionary processes outside such imaginary spaces and make them physically embodied. In other words, we envision the \"Evolution of Things\", rather than just the evolution of digital objects, leading to a new field of Embodied Artificial Evolution (EAE). The main objective of this paper is to present a unifying vision in order to aid the development of this high potential research area. To this end, we introduce the notion of EAE, discuss a few examples and applications, and elaborate on the expected benefits as well as the grand challenges this developing field will have to address.']}\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A paper's abstract can therefore be accessed with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{ int(q[0]['MedlineCitation']['PMID']) : str(q[0]['MedlineCitation']['Article']['Abstract']['AbstractText'][0]) }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "{23144668: 'Evolution is one of the major omnipresent powers in the universe that has been studied for about two centuries. Recent scientific and technical developments make it possible to make the transition from passively understanding to actively using evolutionary processes. Today this is possible in Evolutionary Computing, where human experimenters can design and manipulate all components of evolutionary processes in digital spaces. We argue that in the near future it will be possible to implement artificial evolutionary processes outside such imaginary spaces and make them physically embodied. In other words, we envision the \"Evolution of Things\", rather than just the evolution of digital objects, leading to a new field of Embodied Artificial Evolution (EAE). The main objective of this paper is to present a unifying vision in order to aid the development of this high potential research area. To this end, we introduce the notion of EAE, discuss a few examples and applications, and elaborate on the expected benefits as well as the grand challenges this developing field will have to address.'}"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A paper for which no abstract is available will simply not contain the `'Abstract'` key in its `'Article'` dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_dict( Entrez.read( Entrez.efetch(db=\"pubmed\", id='17782550', retmode=\"xml\") )[0]['MedlineCitation']['Article'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ArticleDate\n",
        "\t[]\n",
        "Pagination\n",
        "\t{u'MedlinePgn': '35'}\n",
        "Language\n",
        "\t['eng']\n",
        "PublicationTypeList\n",
        "\t['Journal Article']\n",
        "Journal\n",
        "\t{u'ISSN': StringElement('0036-8075', attributes={u'IssnType': u'Print'}), u'ISOAbbreviation': 'Science', u'JournalIssue': DictElement({u'Volume': '1', u'Issue': '3', u'PubDate': {u'Month': 'Jul', u'Day': '17', u'Year': '1880'}}, attributes={u'CitedMedium': u'Print'}), u'Title': 'Science (New York, N.Y.)'}\n",
        "ArticleTitle\n",
        "\tEVOLUTION OF LOCOMOTIVES IN AMERICA.\n",
        "ELocationID\n",
        "\t[]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of the ids in our dataset refer to books from the [NCBI Bookshelf](http://www.ncbi.nlm.nih.gov/books/), a collection of freely available, downloadable, on-line versions of selected biomedical books. For such ids, `Entrez.efetch()` returns a slightly different structure, where the keys `[u'BookDocument', u'PubmedBookData']` take the place of the `[u'MedlineCitation', u'PubmedData']` keys we saw above.\n",
      "\n",
      "Here is an example of the data we obtain for the id corresponding to the book [The Social Biology of Microbial Communities](http://www.ncbi.nlm.nih.gov/books/NBK114831/):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = Entrez.read( Entrez.efetch(db=\"pubmed\", id='24027805', retmode=\"xml\") )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_dict( r[0][ 'PubmedBookData' ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ArticleIdList\n",
        "\t[StringElement('24027805', attributes={u'IdType': u'pubmed'})]\n",
        "PublicationStatus\n",
        "\tppublish\n",
        "History\n",
        "\t[DictElement({u'Minute': '0', u'Month': '9', u'Day': '13', u'Hour': '6', u'Year': '2013'}, attributes={u'PubStatus': u'pubmed'}), DictElement({u'Minute': '0', u'Month': '9', u'Day': '13', u'Hour': '6', u'Year': '2013'}, attributes={u'PubStatus': u'medline'}), DictElement({u'Minute': '0', u'Month': '9', u'Day': '13', u'Hour': '6', u'Year': '2013'}, attributes={u'PubStatus': u'entrez'})]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_dict( r[0][ 'BookDocument' ] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PublicationType\n",
        "\t[]\n",
        "KeywordList\n",
        "\t[]\n",
        "AuthorList\n",
        "\t[]\n",
        "Language\n",
        "\t['eng']\n",
        "ArticleIdList\n",
        "\t[StringElement('NBK114831', attributes={u'IdType': u'bookaccession'})]\n",
        "Abstract\n",
        "\t{u'AbstractText': [u'On March 6 and 7, 2012, the Institute of Medicine\\u2019s (IOM\\u2019s) Forum on Microbial Threats hosted a public workshop to explore the emerging science of the \\u201csocial biology\\u201d of microbial communities. Workshop presentations and discussions embraced a wide spectrum of topics, experimental systems, and theoretical perspectives representative of the current, multifaceted exploration of the microbial frontier. Participants discussed ecological, evolutionary, and genetic factors contributing to the assembly, function, and stability of microbial communities; how microbial communities adapt and respond to environmental stimuli; theoretical and experimental approaches to advance this nascent field; and potential applications of knowledge gained from the study of microbial communities for the improvement of human, animal, plant, and ecosystem health and toward a deeper understanding of microbial diversity and evolution.'], u'CopyrightInformation': u'Copyright \\xa9 2012, National Academy of Sciences.'}\n",
        "Book\n",
        "\t{u'Publisher': {u'PublisherLocation': 'Washington (DC)', u'PublisherName': 'National Academies Press (US)'}, u'AuthorList': [ListElement([DictElement({u'Identifier': [], u'CollectiveName': 'Institute of Medicine (US) Forum on Microbial Threats'}, attributes={u'ValidYN': u'Y'})], attributes={u'Type': u'authors', u'CompleteYN': u'Y'})], u'Isbn': ['9780309264327', '0309264324'], u'PubDate': {u'Year': '2012'}, u'BookTitle': StringElement('The Social Biology of Microbial Communities: Workshop Summary', attributes={u'book': u'nap13500'}), u'CollectionTitle': StringElement('The National Academies Collection: Reports funded by National Institutes of Health', attributes={u'book': u'napcollect'}), u'ELocationID': []}\n",
        "ItemList\n",
        "\t[]\n",
        "LocationLabel\n",
        "\t[]\n",
        "PMID\n",
        "\t24027805\n",
        "Sections\n",
        "\t[{u'SectionTitle': StringElement('THE NATIONAL ACADEMIES', attributes={u'part': u'fm.s1', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('PLANNING COMMITTEE FOR A WORKSHOP ON THE MICROBIOME IN HEALTH AND DISEASE', attributes={u'part': u'fm.s2', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('FORUM ON MICROBIAL THREATS', attributes={u'part': u'fm.s3', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('BOARD ON GLOBAL HEALTH', attributes={u'part': u'fm.s5', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('Reviewers', attributes={u'part': u'fm.s7', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('Acknowledgments', attributes={u'part': u'fm.ack', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('Workshop Overview', attributes={u'part': u'workshop', u'book': u'nap13500'}), u'Section': []}, {u'SectionTitle': StringElement('Appendixes', attributes={u'part': u'nap13500.appgroup1', u'book': u'nap13500'}), u'Section': []}]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In a book from the NCBI Bookshelf, its abstract can then be accessed as such:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{ int(r[0]['BookDocument']['PMID']) : conv_str(r[0]['BookDocument']['Abstract']['AbstractText'][0]) }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "{24027805: u'On March 6 and 7, 2012, the Institute of Medicine\\u2019s (IOM\\u2019s) Forum on Microbial Threats hosted a public workshop to explore the emerging science of the \\u201csocial biology\\u201d of microbial communities. Workshop presentations and discussions embraced a wide spectrum of topics, experimental systems, and theoretical perspectives representative of the current, multifaceted exploration of the microbial frontier. Participants discussed ecological, evolutionary, and genetic factors contributing to the assembly, function, and stability of microbial communities; how microbial communities adapt and respond to environmental stimuli; theoretical and experimental approaches to advance this nascent field; and potential applications of knowledge gained from the study of microbial communities for the improvement of human, animal, plant, and ecosystem health and toward a deeper understanding of microbial diversity and evolution.'}"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Abstracts dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now assemble a dataset mapping paper ids to their abstracts."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Abstracts_file = search_term + '__Abstracts.pkl.bz2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import httplib\n",
      "from collections import deque\n",
      "\n",
      "if os.path.exists( Abstracts_file ):\n",
      "    Abstracts = cPickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
      "else:\n",
      "    # `Abstracts` will be incrementally assembled, by performing multiple queries,\n",
      "    # each returning at most `retrieve_per_query` entries.\n",
      "    Abstracts = deque()\n",
      "    retrieve_per_query = 200\n",
      "    \n",
      "    print 'Fetching Abstracts of results: ',\n",
      "    for start in xrange( 0, len(Ids), retrieve_per_query ):\n",
      "        print start,\n",
      "        \n",
      "        # build comma separated string with the ids at indexes [start, start+retrieve_per_query)\n",
      "        query_ids = ','.join( [ str(id) for id in Ids[ start : start+retrieve_per_query ] ] )\n",
      "        \n",
      "        # issue requests to the server, until we get the full amount of data we expect\n",
      "        while True:\n",
      "            try:\n",
      "                s = Entrez.read( Entrez.efetch(db=\"pubmed\", id=query_ids, retmode=\"xml\" ) )\n",
      "            except httplib.IncompleteRead:\n",
      "                print 'r',\n",
      "                continue\n",
      "            break\n",
      "        \n",
      "        i = 0\n",
      "        for p in s:\n",
      "            abstr = ''\n",
      "            if 'MedlineCitation' in p:\n",
      "                pmid = p['MedlineCitation']['PMID']\n",
      "                if 'Abstract' in p['MedlineCitation']['Article']:\n",
      "                    abstr = p['MedlineCitation']['Article']['Abstract']['AbstractText'][0]\n",
      "            elif 'BookDocument' in p:\n",
      "                pmid = p['BookDocument']['PMID']\n",
      "                if 'Abstract' in p['BookDocument']:\n",
      "                    abstr = p['BookDocument']['Abstract']['AbstractText'][0]\n",
      "            else:\n",
      "                raise Exception('Unrecognized record type, for id %d (keys: %s)' % (Ids[start+i], str(p.keys())) )\n",
      "            \n",
      "            Abstracts.append( (int(pmid), conv_str(abstr)) )\n",
      "            i += 1\n",
      "    \n",
      "    # Save Abstracts, as a dictionary indexed by Ids\n",
      "    Abstracts = dict( Abstracts )\n",
      "    \n",
      "    cPickle.dump( Abstracts, bz2.BZ2File( Abstracts_file, 'wb' ), protocol=pickle_protocol )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Taking a look at one paper's abstract:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Abstracts[ 11237011 ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "'The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.'"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can find examples of how to use this data in the \"[text mining](http://nbviewer.ipython.org/urls/raw.github.com/lfsimoes/VU/master/2013__Collective_Intelligence/14__text_mining.ipynb)\" notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ELink: Searching for related items in NCBI Entrez"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<div style=\"float: right\">\n",
      "`Entrez.elink()`: [Biopython Tutorial](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc134), [module documentation](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html#elink), [NCBI's E-utilities reference](http://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.ELink).\n",
      "</div><br><br>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To understand how to obtain paper citations with Entrez, we will first assemble a small set of PubMed IDs, and then query for their citations.\n",
      "To that end, we search here for papers published by [Chris Adami](http://adamilab.msu.edu/) in the [PLOS Computational Biology](http://www.ploscompbiol.org/) journal (as before, having also the word \"evolution\" in either the title or abstract):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CA_search_term = search_term+'[TIAB] AND Adami C[AUTH] AND PLoS computational biology[JOUR]'\n",
      "CA_ids = Entrez.read( Entrez.esearch( db=\"pubmed\", term=CA_search_term ) )['IdList']\n",
      "CA_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "['22028639', '20949101', '18266463']"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CA_summ = {\n",
      "    p['Id'] : ( p['Title'], p['AuthorList'], p['PubDate'][:4], p['FullJournalName'], p.get('DOI', '') )\n",
      "    for p in Entrez.read( Entrez.esummary(db=\"pubmed\", id=','.join( CA_ids )) )\n",
      "    }\n",
      "CA_summ"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "{'18266463': ('Evolution of complex modular biological networks.',\n",
        "  ['Hintze A', 'Adami C'],\n",
        "  '2008',\n",
        "  'PLoS computational biology',\n",
        "  '10.1371/journal.pcbi.0040023'),\n",
        " '20949101': (\"Critical dynamics in the evolution of stochastic strategies for the iterated prisoner's dilemma.\",\n",
        "  ['Iliopoulos D', 'Hintze A', 'Adami C'],\n",
        "  '2010',\n",
        "  'PLoS computational biology',\n",
        "  '10.1371/journal.pcbi.1000948'),\n",
        " '22028639': ('Integrated information increases with fitness in the evolution of animats.',\n",
        "  ['Edlund JA', 'Chaumont N', 'Hintze A', 'Koch C', 'Tononi G', 'Adami C'],\n",
        "  '2011',\n",
        "  'PLoS computational biology',\n",
        "  '10.1371/journal.pcbi.1002236')}"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because we restricted our search to papers in an open-access journal, you can then follow their DOIs to freely access their PDFs at the journal's website:<br>[10.1371/journal.pcbi.0040023](http://dx.doi.org/10.1371/journal.pcbi.0040023), [10.1371/journal.pcbi.1000948](http://dx.doi.org/10.1371/journal.pcbi.1000948), [10.1371/journal.pcbi.1002236](http://dx.doi.org/10.1371/journal.pcbi.1002236)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now issue calls to `Entrez.elink()` using these PubMed IDs, to retrieve the IDs of papers that cite them.\n",
      "The database from which the IDs will be retrieved is [PubMed Central](http://www.ncbi.nlm.nih.gov/pmc/), a free digital database of full-text scientific literature in the biomedical and life sciences.\n",
      "\n",
      "You can, for instance, find [archived here](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2951343/), with the PubMed Central ID 2951343, the paper \"Critical dynamics in the evolution of stochastic strategies for the iterated prisoner's dilemma\", which as we saw above, has the PubMed ID 20949101.\n",
      "\n",
      "A complete list of the kinds of links you can retrieve with `Entrez.elink()` can be found [here](http://eutils.ncbi.nlm.nih.gov/entrez/query/static/entrezlinks.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CA_citing = {\n",
      "    id : Entrez.read( Entrez.elink(\n",
      "            cmd = \"neighbor\",               # ELink command mode: \"neighbor\", returns\n",
      "                                            #     a set of UIDs in `db` linked to the input UIDs in `dbfrom`.\n",
      "            dbfrom = \"pubmed\",              # Database containing the input UIDs: PubMed\n",
      "            db = \"pmc\",                     # Database from which to retrieve UIDs: PubMed Central\n",
      "            LinkName = \"pubmed_pmc_refs\",   # Name of the Entrez link to retrieve: \"pubmed_pmc_refs\", gets\n",
      "                                            #     \"Full-text articles in the PubMed Central Database that cite the current articles\"\n",
      "            from_uid = id                   # input UIDs\n",
      "            ) )\n",
      "    for id in CA_ids\n",
      "    }\n",
      "\n",
      "CA_citing['20949101']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[{u'DbFrom': 'pubmed', u'IdList': ['20949101'], u'LinkSetDbHistory': [], u'LinkSetDb': [{u'DbTo': 'pmc', u'Link': [{u'Id': '3780848'}, {u'Id': '3741637'}], u'LinkName': 'pubmed_pmc_refs'}]}]"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have in `CA_citing[paper_id][0]['LinkSetDb'][0]['Link']` the list of papers citing `paper_id`. To get it as just a list of ids, we can do"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cits = [ l['Id'] for l in CA_citing['20949101'][0]['LinkSetDb'][0]['Link'] ]\n",
      "cits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "['3780848', '3741637']"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, one more step is needed, as what we have now are PubMed Central IDs, and not PubMed IDs. Their conversion can be achieved through an additional call to `Entrez.elink()`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cits_pm = Entrez.read( Entrez.elink( dbfrom=\"pmc\", db=\"pubmed\", LinkName=\"pmc_pubmed\", from_uid=\",\".join(cits)) )\n",
      "cits_pm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "[{u'DbFrom': 'pmc', u'IdList': ['3741637', '3780848'], u'LinkSetDbHistory': [], u'LinkSetDb': [{u'DbTo': 'pubmed', u'Link': [{u'Id': '24003115'}, {u'Id': '23903782'}], u'LinkName': 'pmc_pubmed'}]}]"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids_map = { pmc_id : link['Id'] for (pmc_id,link) in zip(cits_pm[0]['IdList'], cits_pm[0]['LinkSetDb'][0]['Link']) }\n",
      "ids_map"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "{'3741637': '24003115', '3780848': '23903782'}"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And to check that indeed these are the PubMed IDs of papers citing the paper \"Critical dynamics in the evolution of stochastic strategies for the iterated prisoner's dilemma\", you can match PubMed Central's [list of citations for this paper](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2951343/citedby/) against the following results from a query to PubMed for their summaries:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{   p['Id'] : ( p['Title'], p['AuthorList'], p['PubDate'][:4], p['FullJournalName'], p.get('DOI', '') )\n",
      "    for p in Entrez.read( Entrez.esummary(db=\"pubmed\", id=','.join( ids_map.values() )) )\n",
      "    }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "{'23903782': ('Evolutionary instability of zero-determinant strategies demonstrates that winning is not everything.',\n",
        "  ['Adami C', 'Hintze A'],\n",
        "  '2013',\n",
        "  'Nature communications',\n",
        "  '10.1038/ncomms3193'),\n",
        " '24003115': (\"From extortion to generosity, evolution in the Iterated Prisoner's Dilemma.\",\n",
        "  ['Stewart AJ', 'Plotkin JB'],\n",
        "  '2013',\n",
        "  'Proceedings of the National Academy of Sciences of the United States of America',\n",
        "  '10.1073/pnas.1306246110')}"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For comparison, you can match these with Google Scholar's [list of citations](http://scholar.google.com/scholar?cites=13285237943045850451) for the same paper."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Citations dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have now seen all the steps required to assemble a dataset of citations to each of the papers in our dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Citations_file = search_term + '__Citations.pkl.bz2'\n",
      "Citations = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At least one server query will be issued per paper in `Ids`. Because NCBI allows for at most 3 queries per second (see [here](http://biopython.org/DIST/docs/api/Bio.Entrez-pysrc.html#_open)), this dataset will take a long time to assemble. Should you need to interrupt it for some reason, or the connection fail at some point, it is safe to just rerun the cell below until all data is collected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import httplib\n",
      "\n",
      "if Citations == [] and os.path.exists( Citations_file ):\n",
      "    Citations = cPickle.load( bz2.BZ2File( Citations_file, 'rb' ) )\n",
      "\n",
      "if len(Citations) < len(Ids):\n",
      "    \n",
      "    i = len(Citations)\n",
      "    checkpoint = len(Ids) / 10 + 1      # save to hard drive at every 10% of Ids fetched\n",
      "    \n",
      "    for pm_id in Ids[i:]:               # either starts from index 0, or resumes from where we previously left off\n",
      "        \n",
      "        while True:\n",
      "            try:\n",
      "                # query for papers archived in PubMed Central that cite the paper with PubMed ID `pm_id`\n",
      "                c = Entrez.read( Entrez.elink( dbfrom = \"pubmed\", db=\"pmc\", LinkName = \"pubmed_pmc_refs\", id=str(pm_id) ) )\n",
      "                \n",
      "                c = c[0]['LinkSetDb']\n",
      "                if len(c) == 0:\n",
      "                    # no citations found for the current paper\n",
      "                    c = []\n",
      "                else:\n",
      "                    c = [ l['Id'] for l in c[0]['Link'] ]\n",
      "                    \n",
      "                    # convert citations from PubMed Central IDs to PubMed IDs\n",
      "                    p = []\n",
      "                    for start in xrange( 0, len(c), 200 ):\n",
      "                        query_ids = ','.join( c[start : start+200] )\n",
      "                        r = Entrez.read( Entrez.elink( dbfrom=\"pmc\", db=\"pubmed\", LinkName=\"pmc_pubmed\", from_uid=query_ids ) )\n",
      "                        # select the IDs. If no matching PubMed ID was found, [] is returned instead\n",
      "                        p.extend( [] if r[0]['LinkSetDb']==[] else [ int(link['Id']) for link in r[0]['LinkSetDb'][0]['Link'] ] )\n",
      "                    c = p\n",
      "            \n",
      "            except httplib.BadStatusLine:\n",
      "                # Presumably, the server closed the connection before sending a valid response. Retry until we have the data.\n",
      "                print 'r',\n",
      "                continue\n",
      "            break\n",
      "        \n",
      "        Citations.append( (pm_id, c) )\n",
      "        i += 1\n",
      "        print '\\r at %.3f %%' % (100. * i/len(Ids)),\n",
      "        \n",
      "        if i % checkpoint == 0:\n",
      "            print '\\tsaving at checkpoint', i\n",
      "            cPickle.dump( Citations, bz2.BZ2File( Citations_file, 'wb' ), protocol=pickle_protocol )\n",
      "    \n",
      "    print '\\n done.'\n",
      "    \n",
      "    # Save Citations, as a dictionary indexed by Ids\n",
      "    Citations = dict( Citations )\n",
      "    \n",
      "    cPickle.dump( Citations, bz2.BZ2File( Citations_file, 'wb' ), protocol=pickle_protocol )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see that we have indeed obtained the data we expected, you can match the ids below (citations to the paper \"Critical dynamics in the evolution of stochastic strategies for the iterated prisoner's dilemma\"), with the ids listed at the end of last section."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Citations[20949101]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "[24003115, 23903782]"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can find examples of how to use this data in the \"[network analysis](http://nbviewer.ipython.org/urls/raw.github.com/lfsimoes/VU/master/2013__Collective_Intelligence/13__network_analysis.ipynb)\" notebook."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Where do we go from here?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running the code above generates multiple local files, containing the datasets we'll be working with. Loading them into memory is a matter of just issuing a call like<br>\n",
      "``data = cPickle.load( bz2.BZ2File( data_file, 'rb' ) )``.\n",
      "\n",
      "The Entrez module will therefore no longer be needed, unless you wish to extend your data processing with additional information retrieved from PubMed.\n",
      "\n",
      "Should you be interested in looking at alternative ways to handle the data, have a look at the [sqlite3](http://docs.python.org/2/library/sqlite3.html) module included in Python's standard library, or [Pandas](http://pandas.pydata.org/), the Python Data Analysis Library."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}